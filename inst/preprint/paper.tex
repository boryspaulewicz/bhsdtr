% -*- coding: utf-8 -*-

\documentclass[a4paper,man,apacite,floatsintext]{apa6}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{float}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{caption}

\title{The bhsdtr package: a general purpose method of Bayesian
  inference for Signal Detection Theory models}

\shorttitle{The bhsdtr package}

\abstract{We describe a novel method of Bayesian inference for
  hierarchical or non-hierarchical equal-variance normal Signal
  Detection Theory models with one or more criteria. The method is
  implemented as an open-source R package that uses the
  state-of-the-art platform, Stan, for sampling from posterior
  distributions. Our method can accommodate binary responses as well
  as additional ratings and an arbitrary number of nested or crossed
  random grouping factors associated with sensitivity or criteria
  effects. The SDT parameters can be regressed on additional
  predictors within the same model via intermediate unconstrained
  parameters, and the model can be extended by using automatically
  generated human-readable Stan code as a template. In the paper we
  explain how our method improves on other similar available methods,
  we give an overview of the package, demonstrate its ease of use by
  providing a real-study data analysis walk-through, and show that the
  model successfully recovers known parameter values when fitted to
  simulated data.}

\keywords{Signal Detection Theory, rating experiments, Bayesian
  inference, hierarchical models}

\twoauthors{Borysław Paulewicz}{Agata Blaut}

\twoaffiliations{University of Social Sciences and Humanities, Faculty
  in Katowice, Poland}{Department of Psychology, Jagiellonian
  University, Krakow, Poland}

\authornote{

  % This research was supported in part by the National
  % Science Centre, Poland HARMONIA grant given to Michal Wierzchon
  % (2014/14/M/HS6/00911).

  Correspondence concerning this article should be addressed to
  Borysław Paulewicz, Department of Psychology, University of Social
  Sciences and Humanities, Faculty in Katowice, ul. Techników 9,
  40-326 Katowice, Poland.

Contact: bpaulewicz@swps.edu.pl}

\newcommand{\code}[1]{\texttt{#1}}

\begin{document}
\maketitle Many tasks used in psychology studies are essentially
classification tasks. For example, in a memory study participants may
be required to decide if a given test item is old or new, or, in a
perceptual study, an object may be either a letter or a digit. If a
task requires classification, it is always possible that conclusions
based on accuracy or percent correct are invalid because the ability
to discriminate between stimulus classes (i.e., sensitivity) is
confounded with bias, which is a tendency to classify stimuli as
belonging to a particular class \cite{GreenSwets66}. In principle, any
effect that manifests itself in differences in classification accuracy
may reflect differences in sensitivity, bias, or both. Signal
Detection Theory provides a popular solution to this common problem.

However, because the SDT model is non-linear, variability in its
parameters due to factors which are usually study-specific and of no
direct interest to the researcher such as participants or items has to
be accounted for. When they are not accounted for, e.g., by
aggregating the data accros participants or stimuli, the estimates of
SDT parameters are biased. As we explain later in this paper, none of
the available methods of inference for hierarchical SDT models that we
are aware of addresses this problem correctly in it's full generality,
meaning that none of the available methods allows for fixed and random
effects in both the sensitivity and the criteria parameters while
restricting the parameters in accordance with SDT assumptions. Later
in the paper we explain why the \code{bhsdtr} package for R
\cite{rstatistical}, which we have made publicly available at
\code{https://github.com/boryspaulewicz/bhsdtr}, provides a correct
implementation of the general hierarchical linear regression structure
defined on SDT parameters. The package repository also contains the
annotated source code that was used to perform all the analyses and
produce all the figures presented in this paper.

In what follows, after introducing the most common version of the SDT
model, we describe its generalization, which can accommodate data from
rating experiments. Next, we explain briefly why, if a method of
inference for SDT models were to be of general use in psychology
studies, it is essential that it is based on a model equipped with the
hierarchical linear regression structure. The \code{bhsdtr} package
meets this requirement thanks to a novel parametrization. We describe
this novel parametrization and explain how reliance on some popular
parametrizations leads to problems in the two other available
implementations. We end the first part of this paper with a formal
definition of the model as implemented in \code{bhsdtr}. The second
part contains an overview of the package and a tutorial in which we
demonstrate how to use our method in practice. Before we go any
further, however, a note on terminology seems in order.

In the context of hierarchical modelling, factors such as
participants, items, or replications are often referred to as
groups. In our opinion this naming convention may be confusing; a
single participant is both a group and a member of some group, while
at the same time the term "group" is perhaps most strongly associated
with study conditions, as in "experimental group". In this paper we
use the term "sampled factor" instead because, by virtue of being a
new term, it is unambiguous and seems descriptively correct: the term
"sampled factor" seems to capture essential properties of such
variables, i.e., a nominal scale, the fact that values are sampled
from a larger population and are usually not of direct interest, as in
"this is only a sample", and that conclusions of statistical analysis
are meant to apply to the whole population of possible values.

\section{Equal-variance normal SDT model with additional criteria}

According to SDT, each stimulus in a classification task gives rise,
by some unspecified cognitive process, to a unidimensional internal
evidence value $s$ sampled from a distribution that depends on the
stimulus class. For historical reasons the two stimulus classes are
often referred to as "noise" and "signal", and task performance is
described in terms of hits, correct rejections, omissions, and false
alarms, but this terminology is appropriate only when the model is
applied to tasks that require detection, which is far from always
being the case. In the most widely used version of the model, shown in
Fig.~\ref{basicsdt}, the two evidence distributions are normal with
the same variance, often fixed at unity to make the model
identifiable. The distance $d'$ between the means of the evidence
distributions represents sensitivity. Because normal distributions are
unbounded, $s$ is always ambiguous, and so a criterion $c$ placed on
the evidence axis has to be used to reach a binary decision. A
participant is assumed to decide that a stimulus belongs to the first
class (e.g., an old item) if $s < c$, or that it belongs to the second
class (e.g., a new item) if $s \geq c$. The location of the decision
criterion may be interpreted in terms of bias.

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{plot_basicsdt.pdf}
  \caption{Equal-variance normal Signal Detection Theory model}
  \label{basicsdt}
\end{figure}

Perhaps the simplest way of using this model is to fit it to observed
response counts and use the estimated $d'$ values in place of the
percent correct scores; if the model is correct, the resulting
performance measure is not contaminated by bias. The model may not be
correct, which in our view is the most important reason to focus more
on the generalized version shown in Fig.~\ref{sdtr} below.

% Model K >= 2

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{plot_sdtr.pdf}
  \caption{Equal-variance normal Signal Detection Theory model with
    additional criteria}
  \label{sdtr}
\end{figure}

This generalized model is applicable to studies in which participants
are asked to rate their binary classification decisions on confidence
or some other performance- or stimulus-related dimension. The ratings
and the binary classification decisions can be provided together
(e.g., "I am almost certain that it was a digit"), or in an arbitrary
order.

Ratings are accommodated by introducing additional criteria and by
modelling a combined response $y$, which represents both the binary
classification decision and rating as a single number. The value of
$y$ increases with the strength of evidence in favor of the second
stimulus class. For example, if confidence is rated on a four-point
scale, then $y = 1$ when a subject decides that a stimulus belongs to
the first class with certainty $4$, and $y = 5$ when a subject decides
that a stimulus belongs to the second class with certainty $1$. More
formally, if $K$ is the number of possible combined responses, then a
subject is assumed to give response $k$ if $s \in
(\bm{c}_{k-1},\bm{c}_k]$, where $\bm{c}$ are the decision criteria,
  with $\bm{c}_0$ and $\bm{c}_K$ fixed at $-\infty$ and $+\infty$
  respectively.

There is a good reason to collect the ratings and use the generalized
SDT model from Fig.~\ref{sdtr}, even when neither the ratings nor the
placement of criteria are relevant to the research problem. When $K =
2$ (no ratings), the SDT model fits perfectly, regardless of whether
it is a reasonably good approximation to reality, because the data and
the model have the same dimensionality. This makes the generalization
to the $K > 2$ case (i.e., decision with ratings) particularly
important, as it is only when $K > 2$ that the formal assumptions of
the model (e.g., equal or unequal variance) can be tested\footnote{In
  contrast to the formal assumptions, a psychological interpretation
  of the SDT parameters can be tested even when ratings are not
  available, e.g., by means of selective influence
  \cite{sternberg2001separate}}, which is often done by comparing
observed and predicted ROC curves.

When SDT models are used in psychology studies, researchers are
usually interested not in the values of the SDT parameters themselves,
but in relationships between these parameters and additional measured
or manipulated variables; a good example is the dependence of $d'$ on
stimulus strength. Also, in a great majority of psychology studies in
which classification tasks are used, the data have a hierarchical
structure, i.e., there are repeated measures for each participant or
item, and participants or items are only samples from the target
population. A general-purpose method of inference for SDT models
should accommodate both kinds of situations.

\section{The importance of hierarchical regression structure}

If data have a hierarchical structure, but variability due to
subjects, items, or other sampled factors is not accounted for,
estimates of average (fixed) effects are not guaranteed to be unbiased
and conclusions are not guaranteed to generalize to the target
population. The not uncommon practice of analyzing data aggregated
over sampled factors represents an extreme case of ignoring
hierarchical data structure. The invalidity of this approach in the
context of SDT was clearly illustrated with the results of
simulational studies by \citeA{morey2008problematic}; however,
strictly speaking, such demonstrations are irrelevant to prooving the
invalidity in question. Because SDT is a non-linear model, by
definition, when estimates of its parameters are based on data
aggregated over sampled factors (e.g., $d'$ estimated for hits and
false alarms averaged or summed over subjects), the expected values of
these estimates (e.g., what the calculated $d'$ actually estimates)
are not in general true population averages (e.g., true $d'$ in some
condition). Such estimates are biased and inference about a target
population based on them is not valid. To give a concrete example,
consider two unbiased participants, one with $d'_1 = 2$ and one with
$d'_2 = 4$. Their expected average accuracy is given by $(\Phi(d'_1/2)
+ \Phi(d'_2/2)) / 2 = .91$, which corresponds to $d' = 2.68$, whereas
their true average $d'$ is $3$.

Aggregation is not the only way of ignoring a hierarchical data
structure. Sometimes non-aggregated data are analyzed by using
separate estimates for every participant $\times$ item $\times$
condition combination, but uncertainty due to distributions of subject
or item effects is not accounted for by means of a hierarchical model
structure. In such cases, conclusions -- at least with respect to the
uncertainties in estimates of population-average (fixed) effects are
guaranteed to be valid only for the given sample, not the target
population.

Another common source of problems is the separation of estimation of
non-linear model parameters from regression analyses which aim to
relate these parameters to measured or manipulated variables. When the
SDT parameters are estimated separately for each subject and
condition, and only later are these estimates regressed on predictors
of interest, a number of additional issues may arise.

Firstly, the standard errors or credible intervals associated with the
regression coefficients do not reflect the uncertainty in the SDT
parameter estimates because the latter are treated as mere data
points. The precision of parameter estimates often varies between
participants, items, or conditions, but when the estimates are treated
as data points, no use is made of this information. Secondly,
regressing parameters on numeric predictors makes their estimates
dependent on the common regression structure, and so also on each
other, which can improve the quality of the estimates, just as
assuming that random effects are samples from a common distribution
may improve their estimates. The aforementioned problems can be dealt
with by supplementing the SDT model with the hierarchical linear
regression structure.

\section{Comparison with other software implementations}
% \section{Hierarchical Signal Detection Theory in a constrained
%   parameter space}

Both $d'$ and $c$ have the virtue of being directly interpretable in
terms of sensitivity and bias. However, both $d'$ and $c$ are
constrained: $d'$ is non-negative and, when there is more than one
criterion, the elements of the $\bm{c}$ vector are order restricted
($\bm{c}_{i+1} > \bm{c}_i$). Hierarchical linear regression structure
can only be defined on unconstrained parameters, because random
effects are assumed to be normally distributed and normal distribution
is unbounded and because fixed effects are represented by
unconstrained parameters. We provide examples of the problems that may
arise when the SDT model is not correctly reparametrized in the
following summary of two hierarchical SDT implementations. One is the
Gibbs sampler proposed by \citeA{morey2008problematic} and the other
is the Hierarchical Meta-d' model (HMeta-d') proposed by
\citeA{hmetad}. After describing the problems associated with those
two software implementations we will briefly explain how our method
compares to what the otherwise excellent \code{brms} package has to
offer.

The HMeta-d' model is a hierarchical version of the
meta-d' model \cite{maniscalco2012signal}, which in turn is a
generalization of the SDT model that allows for a separate
"meta-sensitivity" to account for possible discrepancies between a
binary stimulus classification (referred to as a type 1 task) and the
associated rating task (referred to as a type 2 or meta-cognitive
task). We consider HMeta-d' here because it reduces to the SDT model
with ratings when the type 1 and type 2 sensitivities are equal.

The Gibbs sampler created by \citeA{morey2008problematic} allows for
at most two sampled factors to have independent normally distributed
random effects on the evidence distribution means. Unlike $d'$, each
evidence distribution mean considered in isolation is an unconstrained
parameter, but the mean of the second evidence distribution is by
definition greater than ($d' > 0$) or equal to ($d' = 0$) the mean of
the first. The authors explicitly admit that their algorithm does not
enforce this restriction because, as they say in the paper, it would
greatly complicate analysis, although nothing more is said about these
complications. At the same time the authors fail to mention that an
immediate consequence of allowing for negative $d'$ values is that the
resulting posterior distribution loses its intended interpretation
since it can have a non-zero mass when $d' < 0$. The outermost
criteria are fixed at $0$ and $1$, and the ordering restriction is
enforced by assuming that the likelihood is $0$ whenever $\bm{c}_{i+1}
\leq \bm{c}_i$. As the authors explain, because a sampled factor can
have independent random effects on the evidence distribution means, it
can have an effect on all the criteria: shifting both means by the
same amount in the same direction is equivalent to keeping the
sensitivity intact, while shifting the criteria relative to the
evidence distributions. However, the elements of the criteria vector
cannot be affected differently by the same sampled factor, which is an
unrealistic restriction: participants differ in how they place the
criteria just as they differ in their sensitivity.

In HMeta-d' the hierarchical structure is restricted to normally
distributed random intercepts of one sampled factor. In the HMeta-d'
model the $d'$ parameter is allowed to assume negative values also,
but the most problematic aspect of this implementation is again the
representation of the criteria. Each element of the criteria vector
has an associated independent normal distribution, which does allow
for criteria random effects, but does not enforce the necessary
ordering restriction. The elements of this vector are sorted to obtain
another criteria vector, and it is this sorted criteria vector that is
used to model the conditional combined response
distributions. Consequently, the model does contain parameters
representing the actual, order-restricted criteria, but, because
sorting is not injective, the space of the actual criteria is only
loosely related (i.e., not isomorphic) to the space of the
unrestricted criteria vectors that are associated with the
hierarchical structure. This makes posterior distributions of random
criteria effects uninterpretable.

% PORÓWNANIE Z brms
Some extensions of the SDT model can be fitted correctly using the
excellent brms package, as described in \citeA{burkner2017brms}. The
brms package is a flexible tool that shares some deep design
similarities with our method. Both our package and the brms belong to
a growing family of software tools that aim to provide a somewhat
simplified and domain or application specific interface to one of the
general purpose bayesian inference engines, in this case the stan
modelling language \cite{carpenter2016stan}. The \code{brms} is a
highly flexible, well documented package that offers an elegant
interface for fitting a large class of mixed models. Among the models
that can be fitted using this package are the ordinal regression
models. The hierarchical SDT model with ratings is essentially a
generalization of mixed ordinal regression, since ratings are an
ordinal-scale variable. However, that does not mean that a general
hierarchical SDT model with ratings can be fitted using the
\code{brms} package. There are three categorical distributions
available at present in brms, i.e., the cumulative model, the adjacent
category model and the sequential model, each with it's own set of
link functions. As the author of the package explains
\cite{burkner2017brms}, the only model that respects the ordering of
the thresholds is the cumulative model. The thresholds in the
cumulative model cannot be regressed on additional variables,
consequently they cannot be associated with random effects.

Another important difference between our method and the \code{brms}
package is that \code{brms} does not utilize the fact that for ordinal
regression models the data can often be significantly aggregated
without loosing any information. For example, if a basic SDT model
with ratings was to be fitted to an arbitrary large dataset using our
method the aggregated dataset would consist of a matrix of dimension
$2\times K$. In that case each iteration of the sampling algorithm
implemented in stan will consist of essentially 2 computations of the
likelihood function, whereas without any aggregation step the number
of such computations will be a linear function of the sample
size. This is especially problematic for high-dimensional non-linear
models such as hierarchical SDT with ratings, because they require
relatively large datasets (i.e., many data points per participant
$\times$ condition).

\section{Hierarchical Signal Detection Theory in an unconstrained
  parameter space}

The general hierarchical linear regression structure can be defined on
SDT parameters only if the latter are derived from unconstrained
parameters. In the \code{bhsdtr} package, $d'$ is derived from
$\delta = \ln(d')$, thus random effects on $d'$ can be modelled by
assuming that $\delta$ is normally distributed. The problem of
representing the criteria by unconstrained parameters is solved by
mapping the $R^{K-1}$ space of unconstrained criteria vectors to the
$K$ dimensional probability simplex space using the softmax function,
and mapping the simplex space to the space of order-restricted
criteria vectors by means of the inverse normal CDF:

\begin{align}
  \bm{c}_i &= \Phi^{-1}(\sum_{k = 1}^i(e^{\bm{\gamma}_k}) /
             \sum_{j=1}^K(e^{\bm{\gamma}_j}))
\label{eq:1}
\end{align}

\noindent where $\Phi$ is the CDF of the standard normal distribution
and $\bm{\gamma} \in R^K$, with $\bm{\gamma}_K$ fixed at $0$ for
identifiability. The idea is illustrated in Fig.~\ref{fig:2} below:

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{plot.pdf}
  \caption{Mapping between the unconstrained $\bm{\gamma}$ vector and
    the criteria}
  \label{fig:2}
\end{figure}

Note that the normal distribution centered at the midpoint is merely a
mapping device, not a third evidence distribution, and that, for the
reasons that will be explained later, it is wider than the two
evidence distributions. The mapping expressed by Eq.~\ref{eq:1} is an
isomorphism between the $R^{K-1}$ space and the space of
order-restricted criteria vectors. It's inverse is given by
$\gamma_i =\ln{(\int_{c_{i-1}}^{c_i} f(s) \,ds /
  \int_{c_{K-1}}^{\infty} f(s) \, ds)}$, where $f$ is the standard
normal probability density function. The elements of the $\bm{\gamma}$
vector correspond to relative distances between pairs of adjacent
criteria because their exponents represent the relative magnitudes of
areas under the standard normal curve, delineated by the pairs of
adjacent criteria:
$e^{\bm{\gamma}_i} / e^{\bm{\gamma}_j} = (\Phi(\bm{c}_i) -
\Phi(\bm{c}_{i-1})) / (\Phi(\bm{c}_j) - \Phi(\bm{c}_{j-1}))$. When
$K=2$, only $\bm{\gamma}_1$ is free to vary, and its value directly
represents the direction and magnitude of bias: $\bm{\gamma}_1$ is $0$
when the criterion is placed at the midpoint between the evidence
distributions; the more negative (positive) $\bm{\gamma}_1$ is, the
more the criterion is shifted to the left (right) of the midpoint.

It is often a good idea to multiply all the criteria by a value
greater than $1$, which is equivalent to making the mapping
distribution wider. This tends to even out values of $\bm{\gamma}$ by
preventing the outermost areas under the mapping distribution curve
from becoming very small relative to ares delineated by adjacent pairs
of non-outermost criteria. This is especially important when the
criteria are widely spread, as can happen for moderate to large $d'$
values. This feature is implemented in the \code{bhsdtr} package by
introducing a criteria scaling factor.

Once $d'$ and $c$ are derived from the unconstrained $\delta$ and
$\gamma$ parameters, the SDT model can be supplemented with a
hierarchical linear regression structure. To avoid having to deal with
an even more complicated index notation\footnote{The reader familiar
  with hierarchical models may be surprised by our use of superscript
  parenthesized Greek letters to express hierarchical
  relationships. We chose this convention because it allowed us to use
  subscripts to denote elements of vectors and matrices while
  minimizing the number of nested sub- or superscripts.}, below we
present only the simple case of one sampled factor.

\begin{align*}
  \bm{\delta} &= \bm{X}^{(\delta)} \bm{\beta}^{(\delta)} + \bm{Z}^{(\delta)} \bm{\theta}^{(\delta)} \\
  \bm{d'}_i &= e^{\bm{\delta}_i} \\
  \bm{\gamma}_{i,\cdot} &= \bm{X}^{(\gamma)}_{i,\cdot} \bm{\beta}^{(\gamma)} + \bm{Z}^{(\gamma)}_{i,\cdot}
                      \bm{\theta}^{(\gamma)} \\
  \bm{c}_{i,k} &= s \ \Phi^{-1}(\sum_{l = 1}^k(e^{\bm{\gamma}_{i,l}}) /
                 \sum_{m=1}^K(e^{\bm{\gamma}_{i,m}})) \\
  p(\bm{y}_i = k|\bm{stim}_i = 1) &= \Phi(\bm{c}_{i,k} + \bm{d'}_i / 2) - \Phi(\bm{c}_{i,k-1} + \bm{d'}_i / 2) \\
  p(\bm{y}_i = k|\bm{stim}_i = 2) &= \Phi(\bm{c}_{i,k} - \bm{d'}_i / 2) - \Phi(\bm{c}_{i,k-1} - \bm{d'}_i / 2)
\end{align*}

\noindent Here $i = 1\dots N$ is the observation number, $\bm{X}$ is
the fixed effects model matrix for the respective parameter, $\bm{Z}$
is the random effects model matrix, $\bm{\beta}$ and $\bm{\theta}$ are
the fixed and random effects, $\bm{c}$ is an $N \times K-1$ matrix,
$s$ is the criteria scaling factor, and $\bm{y}$ is the combined
response. Note that $\bm{d'}_i$ is a scalar, but
$\bm{\gamma}_{i,\cdot}$ is in general a vector, and so
$\bm{\beta}^{(\gamma)}$ and $\bm{\theta}^{(\gamma)}$ are matrices. The
$j$-th rows of the $\bm{\beta}^{(\gamma)}$ and
$\bm{\theta}^{(\gamma)}$ matrices represent fixed and random effects
on the $j$-th element of the $\bm{\gamma}$ vector.

Following \citeA{sorensen2015bayesian} we make use of the Cholesky
decomposition of the correlation matrices because it improves
efficiency and admits a convenient prior on random effects
correlations:

\begin{align*}
  \text{vectorized}(\bm{\theta}^{(\gamma)}) &= \text{diag}(\bm{\tau}^{(\gamma)}) \bm{L}^{(\gamma)} \bm{z}^{(\gamma)} \\
  \bm{\theta}^{(\delta)} &= \text{diag}(\bm{\tau}^{(\delta)}) \bm{L}^{(\delta)} \bm{z}^{(\delta)} \\
  \bm{z}^{(\delta)}_i &\sim \text{Normal}(0, 1) \\
  \bm{z}^{(\gamma)}_j &\sim \text{Normal}(0, 1)
\end{align*}

\noindent where each $\bm{\tau}$ is a vector of standard deviations of
random effects and each $\bm{L}$ is a Cholesky decomposition of a
random effects correlation matrix, i.e., $\bm{C} = \bm{L}
\bm{L}'$. Thus, $\bm{\theta}$ is multivariate normal with covariance
matrix $\text{diag}(\bm{\tau}) \bm{L}$.

Finally, we use weakly informative proper priors because they provide
regularization and help stabilize computation. The fixed effects
$\bm{\beta}^{(\delta)}$ and $\bm{\beta}^{(\gamma)}$ are given
independent normal priors, the random effects standard deviations
$\bm{\tau}^{(\delta)}$ and $\bm{\tau}^{(\gamma)}$ are given
independent half-Cauchy priors, as recommended by
\citeA{gelman2004prior}, and each $\bm{L}$ is given an independent lkj
prior:

\begin{align*}
  \bm{\beta}^{(\delta)}_i &\sim \text{Normal}(\bm{\mu}^{(\delta)}_i, \bm{\sigma}^{(\delta)}_i) \\
  \bm{\beta}^{(\gamma)}_{k,l} &\sim \text{Normal}(\bm{\mu}^{(\gamma)}_{k,l}, \bm{\sigma}^{(\gamma)}_{k,l}) \\
  \bm{\tau}^{(\delta)}_i &\sim \text{half-Cauchy}(0, \bm{\zeta}^{(\delta)}_i) \\
  \bm{\tau}^{(\gamma)}_{k,l} &\sim \text{half-Cauchy}(0, \bm{\zeta}^{(\gamma)}_{k,l}) \\
  \bm{L}^{(\delta)} &\sim \text{lkj}(\nu^{(\delta)}) \\
  \bm{L}^{(\gamma)} &\sim \text{lkj}(\nu^{(\gamma)}) \\
\end{align*}

\section{Specifying the prior distributions}

% BOOTSTRAPOWANIE PRIORÓW NA PODST VARIACYJNEGO BAYESA

A Bayesian model is not complete without providing fixed values of all
the parameters that define prior distributions. Specifying the priors
on sensitivity effects does not pose any special difficulties. The
sensitivity of an unbiased classifier given percent correct (pc) is
given by $2 \Phi^{-1}(\text{pc})$. When $p(stim = 1) = 0.5$, the
greater the bias, the lower the accuracy, meaning that an unbiased
sensitivity is a lower bound on sensitivity given percent correct. Let
us assume that the majority of subjects are expected to achieve
percent correct within the $.51$ to $.99$ range, with negligible
bias. Since $\ln(2\Phi^{-1}(.51)) = -2.99$ and
$\ln(2 \Phi^{-1}(.99)) = 1.54$, a reasonable weakly informative prior
on $\delta$ is normal with mean $(1.54 - 2.99) / 2$ and standard
deviation $(1.54 + 2.99) / 2$, which is the default prior on delta
effects in the \code{bhsdtr} package.

Specifying the priors on criteria effects can be challenging because
the criteria are order-restricted and the complexity of the mapping
expressed by Eq.~\ref{eq:1} makes it difficult to reason about priors
on $\bm{\gamma}$ in terms of criteria effects. By default, in the
\code{bhsdtr} package each entry in the $\bm{\sigma}^{(\gamma)}$ and
$\bm{\zeta}^{(\gamma)}$ matrices is set to $\ln(100)$ and the criteria
scaling factor is fixed at $2$.

The prior on random effects standard deviations is parametrized by
$\bm{\zeta}$, which represents half-width at half-maximum of the
half-Cauchy distribution. In our opinion, a not-unreasonable starting
point is to set $\bm{\zeta}$ at the value that is greater or equal to
the most likely value of the random effects standard deviation.

Finally, by default $\nu^{(\delta)} = \nu^{(\gamma)} = 1$, which
implies a uniform prior on random effects correlation
matrices. Because the greater the value of $\nu$, the more emphasis is
put on zero off-diagonal correlations, the researcher can force the
correlations to be near-zero by choosing a large $\nu$ value.

\section{Overview of the software implementation}

The \code{bhsdtr} package implements the model in the Stan modelling
language because the stan sampler uses a state-of-the-art adaptive
Hamiltonian Monte Carlo algorithm which often handles high-dimensional
correlated posteriors better than a Gibbs sampler.

Our package is essentially a collection of documented functions: The
\code{aggregate\_responses} function aggregates data as much as
possible for efficiency, but without distorting the hierarchical
structure. The \code{make\_stan\_model} function creates a model
definition in the Stan language. The Stan code produced by the
\code{make\_stan\_model} function can be fitted as is or modified by
the user if needed, e.g., to change the prior distributions or to drop
the equal variance assumption. The \code{make\_stan\_data} function
creates regression model matrices and other data structures required
by the model created using the \code{make\_stan\_model}
function. Finally, the \code{plot\_sdt\_fit} function can be used to
visually assess the fit of the model by creating publication-ready ROC
curve plots or response distribution plots with posterior predictive
intervals calculated for the chosen $\alpha$ level.

\subsection{Usage example: installing the package and testing the
  model on real data}

To make full use of the \code{bhsdtr} package functionality, three
non-standard R packages are required, namely \code{rstan},
\code{plyr}, and \code{ggplot2}. We recommend using the
\code{devtools} package to install the \code{bhsdtr} package directly
from the github repository. This will automatically install the
package and any missing required packages:

\begin{lstlisting}{language = R}
  devtools::install_git('git://github.com/boryspaulewicz/bhsdtr')
  library(bhsdtr)
\end{lstlisting}

The essential steps of a typical data analysis process will usually
involve preparing the data, creating the model code, fitting the
model, assessing the fit, and possibly converting the unconstrained
$\delta$ and $\gamma$ parameters to $d'$ and $c$.

\subsubsection{Preparing the data}

The \code{bhsdtr} package contains a dataset, \code{gabor}, from an
unpublished study in which on each trial the participants had to
classify a briefly presented Gabor patch as tilted to the left or to
the right using the arrow keys. The participants were also asked to
rate the stimuli on a 4-point Perceptual Awareness Scale
\cite{ramsoy2004introspection} presented at the bottom of the
screen. The Gabor patch was immediately followed by a mask. The PAS
ratings ranged from "no experience" to "absolutely clear image" and
were provided either before (RD order condition) or after (DR order
condition) the arrow keys were pressed. On each trial the Gabor patch
was equally likely to be presented for 32 ms or 64 ms. Order was a
between-subject variable and duration was a within-subject
variable. There were 47 participants and 48 trials per condition.

In the study in question, the response was originally encoded using
separate variables for accuracy and rating, so the first step was to
create an appropriate response variable using the
\code{combined\_response} function. This function requires three
variables, one encoding the stimulus class, one encoding the rating
(as an integer), and one binary variable encoding the decision
accuracy.

\begin{lstlisting}{language=R}
  gabor$resp = combined_response(gabor$stim, 
                                 gabor$rating, 
                                 gabor$acc)
\end{lstlisting}

This step is required only if the ratings are available and a combined
response variable is not already present in the data. In the single
criterion case, the combined response variable is simply the binary
classification decision. To fit a single-criterion SDT model to this
dataset, the code above would have to be replaced with the following:

\begin{lstlisting}{language=R}
  gabor$resp = combined_response(gabor$stim, 
                                 accuracy = gabor$acc)
\end{lstlisting}

Next, the data has to be aggregated using the
\code{aggregate\_responses} function, but only to an extent that
preserves all the random effects. This function requires as arguments
a data frame containing all the relevant variables, the name of the
stimulus class variable, the name of the combined response variable,
and the vector of the names of all the variables that are to be
preserved in the resulting aggregated dataset (apart from the stimulus
class variable and the combined response variable), i.e., those
encoding the sampled factors and those representing the independent
variables used in the regression part of the model:

\begin{lstlisting}{language=R}
adata = aggregate_responses(gabor, 'stim', 'resp', 
                            c('id', 'duration', 'order'))  
\end{lstlisting}

The main purpose of the aggregation step is to improve the efficiency
of sampling from the posterior distribution. When data are aggregated
in this way, the likelihood for each condition $\times$ participant
combination has to be computed only once rather than as many times as
there are trials per condition per participant. Note that if there are
other sampled factors present in the data (e.g., items, replications,
etc.) and the user decided to model the effects of these factors, then
these factors also have to be specified at this stage to preserve the
hierarchical data structure. The \code{aggregate\_responses} function
creates a list with three components. The \code{data} component is a
data frame containing additional preserved variables, the
\code{stimulus} component is the stimulus class variable, and the
\code{counts} component is an $N\times K$ matrix of combined response
counts, where $N$ is the number of data points and $K$ is the number
of possible combined response values.

\subsubsection{Creating the model code}

A model is fitted using the \code{stan} function from the \code{rstan}
package. This function requires a special list of data structures used
by the model as well as a model specification expressed in the Stan
language.

Every model has some fixed effects structure since, even when there
are no predictors, the model parameters can be expressed as regressed
on a vector of ones (i.e., an intercept). However, many models also
have a hierarchical structure and, if that is the case, this
hierarchical structure has to be specified when using the
\code{make\_stan\_model} function. This is done by providing a list of
lists of R model formulae. Each list of model formulae is composed of
at least three elements and specifies the correlated random effects of
one sampled factor. The \code{group} element specifies the sampled
factor; the \code{delta} and \code{gamma} elements specify which
effects are assumed to vary between the levels of this sampled
factor. When \code{make\_stan\_model} is used without any arguments,
it specifies a model without any random effects. Fixed effects model
matrices are specified by providing a list with at least two model
formulae, named \code{delta} and \code{gamma}, to the
\code{make\_stan\_data} function that is described later in this
paper. Non-default priors can be specified by adding optional elements
to the random and fixed effects specification lists, as described in
the \code{make\_stan\_data} function documentation.

In the study in question there was only one sampled factor, i.e., the
participants. Because duration was a within-participant variable, in
principle its effect could vary between the participants for all the
SDT parameters. However, a preliminary data analysis indicated that
the 32 ms difference in duration seemed to affect only the
sensitivity. Thus, it was assumed that $\delta$ may depend on duration
and order, but $\gamma$ may only be affected by order. Because
duration was a within-subjects variable, its effect on $\delta$ was
assumed to vary between the participants, but the only random effect
associated with $\gamma$ was the intercept.

\begin{lstlisting}{language=R}
fixed = list(delta = ~ -1 + duration:order, 
             gamma = ~ order)
random = list(list(group = ~ id, 
              delta = ~ -1 + duration, 
              gamma = ~ 1))
model = make_stan_model(random)
\end{lstlisting}

The \code{make\_stan\_data} function creates fixed and random effect
model matrices based on the respective model formulae using dummy
contrast coding. Note that the implicit intercept was removed for the
$\delta$ model matrix (the $-1$ term on the right hand side of the
model formula). In this way, $\delta$ was estimated for every duration
$\times$ order condition. The resulting separate intercepts and slopes
parametrization makes it easier to calculate arbitrary contrasts on
posterior samples. A more standard parametrization was used for the
$\gamma$ parameter because it was initially assumed that the criteria
depend only on order, which is a two-level factor, and so there was
only one contrast of interest for every element of the $\gamma$
vector. On the other hand, even in such cases the parametrization with
separate intercepts and slopes for every condition may be more
convenient if a researcher is interested in the actual criteria, as we
will later explain when introducing the \code{gamma\_to\_crit}
function. This example also illustrates how the separation of the
$\delta$ and $\gamma$ regression structures makes it possible to test
a broad class of linear models representing the dependence of the SDT
parameters on additional variables.

\subsubsection{Fitting the model}

In order to fit the model, a separate data structure used by the Stan
sampler has to be created using the \code{make\_stan\_data}
function. The obligatory arguments to this function are an aggregated
data object created by the \code{aggregate\_responses} function and a
fixed effects specification. Importantly, if random effects are
modelled, the same specification of random effects has to be provided
to the \code{make\_stan\_model} and \code{make\_stan\_data} functions.

\begin{lstlisting}{language=R}
sdata = make_stan_data(adata, fixed, random)
\end{lstlisting}

Finally, a vector of names of parameters of interest has to be
specified when calling the \code{stan} function:

\begin{lstlisting}{language=R}
fit = stan(model_code = model,
           data = sdata,
           pars = c('delta_fixed', 'gamma_fixed',
                    'delta_sd_1', 'gamma_sd_1',
                    'delta_random_1', 'gamma_random_1',
                    'Corr_delta_1', 'Corr_gamma_1',
                    'counts_new'),
           iter = 8000,
           chains = 4)
\end{lstlisting}

Note that since more than one sampled factor is allowed, the names of
all the hierarchical parameters are indexed (e.g.,
\code{delta\_sd\_1}, \code{delta\_random\_1},
\code{Corr\_delta\_1}). The name \code{counts\_new} refers to
posterior predictive samples that are required by the
\code{plot\_sdt\_fit} function. Names starting with \code{Corr} refer
to random effects correlation matrices.

\subsubsection{Assessing the model fit}

As can be seen in the previous code fragment four chains of 8,000
iterations each were run simultaneously; the first half of the
posterior samples, which served as a warm-up period for tuning the
parameters of the sampling algorithm, was discarded. Part of the
resulting Stan output is presented in Table~\ref{fitsum} below.

\begin{table}[H]
\caption{Model fit summary statistics}
\begin{tabular}{rrrrrrrr}
  % \hline
  & mean & $SE_{mean}$ & $SD$ & $2.5\%$ & $97.5\%$ & No. eff. samples & $\hat{R}$ \\ 
  \hline
  delta\_fixed[1] & -0.10 & 0.00 & 0.15 & -0.41 & 0.18 & 4626 & 1.00 \\ 
  delta\_fixed[2] & 1.12 & 0.00 & 0.09 & 0.95 & 1.29 & 4764 & 1.00 \\ 
  delta\_fixed[3] & -0.39 & 0.00 & 0.20 & -0.80 & -0.03 & 5427 & 1.00 \\ 
  delta\_fixed[4] & 1.28 & 0.00 & 0.11 & 1.06 & 1.50 & 5464 & 1.00 \\ 
  gamma\_fixed[1,1] & -0.14 & 0.00 & 0.06 & -0.27 & -0.02 & 2925 & 1.00 \\ 
  gamma\_fixed[1,2] & -0.22 & 0.00 & 0.10 & -0.42 & -0.01 & 8199 & 1.00 \\ 
  gamma\_fixed[2,1] & -0.70 & 0.00 & 0.18 & -1.05 & -0.35 & 3060 & 1.00 \\ 
  gamma\_fixed[2,2] & 0.49 & 0.00 & 0.29 & -0.06 & 1.04 & 3452 & 1.00 \\ 
  gamma\_fixed[3,1] & -0.54 & 0.00 & 0.22 & -0.96 & -0.11 & 3103 & 1.00 \\ 
  gamma\_fixed[3,2] & 0.83 & 0.01 & 0.35 & 0.14 & 1.51 & 3086 & 1.00 \\ 
  gamma\_fixed[4,1] & 0.28 & 0.00 & 0.25 & -0.20 & 0.76 & 3090 & 1.00 \\ 
  gamma\_fixed[4,2] & 0.42 & 0.01 & 0.40 & -0.37 & 1.22 & 3291 & 1.00 \\ 
  gamma\_fixed[5,1] & -0.21 & 0.01 & 0.30 & -0.80 & 0.37 & 3440 & 1.00 \\ 
  gamma\_fixed[5,2] & 0.83 & 0.01 & 0.48 & -0.10 & 1.78 & 3637 & 1.00 \\ 
  gamma\_fixed[6,1] & -0.77 & 0.00 & 0.24 & -1.23 & -0.31 & 3378 & 1.00 \\ 
  gamma\_fixed[6,2] & 0.80 & 0.01 & 0.38 & 0.05 & 1.56 & 3316 & 1.00 \\ 
  gamma\_fixed[7,1] & -0.32 & 0.00 & 0.16 & -0.64 & 0.01 & 3346 & 1.00 \\ 
  gamma\_fixed[7,2] & 0.42 & 0.00 & 0.28 & -0.11 & 0.98 & 3333 & 1.00 \\ 
  delta\_sd\_1[1] & 0.66 & 0.00 & 0.11 & 0.48 & 0.90 & 6373 & 1.00 \\ 
  delta\_sd\_1[2] & 0.44 & 0.00 & 0.05 & 0.35 & 0.56 & 5463 & 1.00 \\ 
  gamma\_sd\_1[1] & 0.16 & 0.00 & 0.08 & 0.02 & 0.31 & 2071 & 1.00 \\ 
  gamma\_sd\_1[2] & 0.82 & 0.00 & 0.11 & 0.62 & 1.06 & 5852 & 1.00 \\ 
  gamma\_sd\_1[3] & 1.08 & 0.00 & 0.12 & 0.86 & 1.33 & 4293 & 1.00 \\ 
  gamma\_sd\_1[4] & 1.27 & 0.00 & 0.14 & 1.03 & 1.57 & 3723 & 1.00 \\ 
  gamma\_sd\_1[5] & 1.55 & 0.00 & 0.17 & 1.24 & 1.91 & 4297 & 1.00 \\ 
  \dots{} & \dots{} & \dots{} & \dots{} & \dots{} & \dots{} & \dots{} & \dots{} \\
  \hline
\end{tabular}
\label{fitsum}
\end{table}

Given the complexity of the model the chains exhibited good mixing and
seemed to have converged; there were enough effective posterior
samples for the fixed effect parameters to estimate $95\%$ credible
intervals well and none of the Gelman-Rubin $\hat{R}$ statistics
crossed the conventional $1.01$ threshold, suggesting negligible
sensitivity to the initial values.

Figs.~\ref{fig:6} and \ref{fig:7} below contain normal
quantile-quantile plots of random effects. The plots indicate that the
distributions of random $\delta$ and $\gamma$ effects can be
approximated by normal distributions and that -- at least in this
particular example -- these parameters seem to be good candidates for
representing variability in the sensitivity and criteria parameters
due to the sampled factors.

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{delta_qq_plot.pdf}
  \caption{Normal quantile-quantile plots of $\delta$ random effects}
  \label{fig:6}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{gamma_qq_plot.pdf}
  \caption{Normal quantile-quantile plots of $\gamma$ random effects}
  \label{fig:7}
\end{figure}

Once enough good quality posterior samples are obtained for the
parameters of interest, the inference process can be carried out by
calculating credible intervals or HPD intervals for any function of
the parameters or Bayes factors for each parameter
separately. However, even when the stan output summary does not
indicate sampler convergence issues, before drawing any further
conclusions the researcher should first check if the model fits the
data. The \code{plot\_sdt\_fit} function can be used for this purpose:

\begin{lstlisting}{language = R}
plot_sdt_fit(fit, adata, c('order', 'duration')))
\end{lstlisting}

This function requires at least three arguments: a \code{stanfit}
object, an aggregated data list produced by the
\code{aggregate\_responses} function that was used to produce the
stanfit object, and a vector of names of variables that will determine
how the data will be partitioned before plotting. We recommend
assessing the fit at the individual level by including the participant
identification number in the list of conditioning variables, but we
did not do it here because the resulting plot would take up too much
space.

As can be seen in Fig.~\ref{fig:3}, which shows the ROC curves
produced by the code above, the model seemed to fit the data well in
all but one condition (decision after rating, 64 ms duration), in
which three out of seven relevant\footnote{The point in the
  upper-right corner of a ROC curve is always in the $(1,1)$ position}
points were outside the two-dimensional $95\%$ posterior predictive
regions.

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{roc_fit.pdf}
  \caption{ROC curve fit}
  \label{fig:3}
\end{figure}

Another way to assess model fit visually is by inspecting the
conditional response distributions ($p(y|stim)$), such as those shown
in Fig.~\ref{fig:4}, which was also created using the
\code{plot\_sdt\_fit} function.

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{response_fit.pdf}
  \caption{Response distribution fit}
  \label{fig:4}
\end{figure}

Both plots can be informative about the reasons why a model does not
fit the data. In this particular case, the plot seems to suggest that
it may be a good idea to inspect the fit at the individual level and
see if there are some participants with unusual $p(y|stim=1)$
distributions in the RD $\times$ 64 ms condition. On the other hand,
it is also possible that the lack of fit is mainly a consequence of
the assumption that duration had zero effect on $\bm{\gamma}$, or that
more substantial modifications are necessary, such as dropping the
equal variance assumption.

\subsubsection{Converting unconstrained $\delta$ and $\gamma$
  parameters to sensitivities and criteria}

Posterior $\delta$ and $\gamma$ samples have to be transformed in
order to work with the $d'$ and $c$ parameters. This is
straightforward only when fixed effects represent average parameter
values in separate conditions, not when they represent differences
between conditions or regression slopes. In our example, because
separate intercepts and slopes parametrization was used for the
$\delta$ fixed effects model matrix, all four \code{delta\_fixed}
parameters represent condition averages and can easily be transformed
to sensitivities by applying the exponential function. It is important
to remember that because this is a non-linear transformation, the
$\delta$ to $d'$ conversion step should be done first before applying
any other transformations to the posterior samples; for example, the
exponential of a point and interval estimate of $\delta$ is not equal
to the point and interval estimate calculated after first transforming
the $\delta$ posterior samples to the $d'$ samples.

In this case the first column of the \code{gamma\_fixed} parameter
matrix (the intercept) corresponds to the values of the $\bm{\gamma}$
vector in the DR condition, but the second column corresponds to the
\emph{effect} of order on $\bm{\gamma}$. For this reason, in this
particular case the posterior criteria samples can be obtained using
the \code{gamma\_to\_crit} function only for the first column of the
\code{gamma\_fixed} matrix. That's because the second column
represents the \emph{difference} in $\bm{\gamma}$ between conditions
and a nonlinear transformation from $\bm{\gamma}$ to $\bm{c}$ will not
give a correct difference in $\bm{c}$.

\subsection{Testing the model on simulated data}

We simulated the data from a hypothetical exact replication of the
previously described experiment using the point estimates from the
previous fit as known realistic parameter values. Mixing performance
was similar to the real data case. All the model parameters were
correctly recovered in a sense that the true values were outside the
$95\%$ credible intervals no more than $5\%$ of the time.

As we have repeatedly stressed the models that lack the necessary
hierarchical structure may easily show reliable effects where none
exist or fail to detect true differences. To illustrate this problem,
an SDT model that differed from the true model only in that it did not
have any hierarchical structure was fitted to the same simulated
dataset. Tring to obtain general theoretical results on the typical
extent of bias in models that ignore the hierarchical structure would
be a serious undertaking, but even this simple simulational example
shows how misleading can the results of such analyses be. Since the
non-hierarchical model was much simpler and the data consisted of only
eight vectors of response counts, the mixing of the chains was
excellent.

The $95\%$ credible intervals calculated for the fixed effects based
on each model are compared in Fig.~\ref{fig:5} below. The estimates
were centered on the true values to simplify the presentation. As can
be seen, the true model correctly recovered the known parameter
values, but the estimates based on the simplified, non-hierarchical
model were severely biased; the credible intervals were not only about
three times shorter on average, but also failed to contain most of the
true values.

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{true_vs_nonhier.pdf}
  \caption{Comparison of the point and interval posterior estimates
    based on the true hierarchical and the simplified non-hierarchical
    models}
  \label{fig:5}
\end{figure}

To avoid bias, the hierarchical structure present in the data can be
reduced or ignored only if the fit of the full hierarchical model
indicates that the random effect variances or correlations are likely
to be equal to zero. Importantly, this rule is valid regardless of the
apparent fit of the model, as illustrated by the contents of
Fig.~\ref{fig:8} below; even though the simplified model provided
strongly biased results the observed ROC curves seemed to fit the
model's predictions quite well, giving a false impression of model
validity.

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{roc_sim_aggr_fit.pdf}
  \caption{ROC curve fit for the non-hierarchical model}
  \label{fig:8}
\end{figure}

\section{Concluding remarks}

The importance of SDT to psychology stems from the fact that given
weak assumptions about an underlying decision process, it promises to
deconfound sensitivity from bias in arbitrary binary classification
tasks - a problem almost as common in psychology studies as the usage
of classification tasks. To the best of our knowledge, at present the
\code{bhsdtr} package provides the only method of Bayesian inference
for SDT models with or without ratings that can be recommended as a
default choice in typical applications. Our parametrization forces the
sensitivity to be non-negative and the criteria to be
order-restricted, while the isomorphisms between the $d'$ and $c$
parameters and the unconstrained $\delta$ and $\gamma$ parameters make
it possible to supplement the SDT model with the general hierarchical
linear regression structure. There is no limit to the number of
sampled factors except for the one imposed by available computational
resources; correlations of random effects of the same sampled factor
are accounted for, all the SDT parameters can be modelled by linear
regression within the same model, and all the effects on all the SDT
parameters estimable within the levels of the sampled factors can have
associated random effects. If the need arises to relax a built-in
restriction, experienced users can extend the model in arbitrary ways
by using automatically generated human-readable Stan code as a
template.
% We hope that researchers with a basic understanding of Signal
% Detection Theory, Bayesian inference, and hierarchical modelling will
% find our package useful and adopt it as a method of analysis of binary
% classification performance in future studies.

\bibliography{/home/borys/cs/literatura}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper.toc"
%%% End:
