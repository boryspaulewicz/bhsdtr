% -*- coding: utf-8 -*-

\documentclass[a4paper,man,apacite,floatsintext]{apa6}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{float}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{caption}

\title{The bhsdtr package: a general purpose method of Bayesian
  inference for Signal Detection Theory models}

\shorttitle{The bhsdtr package}

\abstract{We describe a novel method of Bayesian inference for
  hierarchical or non-hierarchical equal-variance normal Signal
  Detection Theory models with one or more criteria. The method is
  implemented as an open-source R package that uses the
  state-of-the-art platform, Stan, for sampling from posterior
  distributions. Our method can accommodate binary responses as well
  as additional ratings and an arbitrary number of nested or crossed
  random grouping factors. The SDT parameters can be regressed on
  additional predictors within the same model via intermediate
  unconstrained parameters, and the model can be extended by using
  automatically generated human-readable Stan code as a template. In
  the paper we explain how our method improves on other similar
  available methods, we give an overview of the package, demonstrate
  its ease of use by providing a real-study data analysis
  walk-through, and show that the model successfully recovers known
  parameter values when fitted to simulated data.}

\keywords{Signal Detection Theory, rating experiments, Bayesian
  inference, hierarchical models}

\twoauthors{Borysław Paulewicz}{Agata Blaut}

\twoaffiliations{University of Social Sciences and Humanities, Faculty
  in Katowice, Poland}{Department of Psychology, Jagiellonian
  University, Krakow, Poland}

\authornote{This research was supported in part by the National
  Science Centre, Poland HARMONIA grant given to Michal Wierzchon
  (2014/14/M/HS6/00911).

  Correspondence concerning this article should be addressed to
  Borysław Paulewicz, Department of Psychology, University of Social
  Sciences and Humanities, Faculty in Katowice, ul. Techników 9,
  40-326 Katowice, Poland.

Contact: bpaulewicz@swps.edu.pl}

\newcommand{\code}[1]{\texttt{#1}}

\begin{document}
\maketitle
Many tasks used in psychology studies are essentially classification
tasks. For example, in a memory study participants may be required to
decide if a given test item is old or new, or, in a perceptual study,
an object may be either a letter or a digit. If a task requires
classification, it is always possible that conclusions based on
accuracy or percent correct are invalid because the ability to
discriminate between stimulus classes (i.e., sensitivity) is
confounded with bias, which is a tendency to classify stimuli as
belonging to a particular class \cite{GreenSwets66}. In principle, any
effect that manifests itself in differences in classification accuracy
may reflect differences in sensitivity, bias, or both. Signal
Detection Theory provides a simple and popular solution to this common
and important problem.

However, because the SDT model is non-linear, variability in its
parameters due to factors such as participants or items has to be
accounted for, otherwise the estimates of SDT parameters are
biased. As we explain later in this paper, neither of the two
available methods of inference for hierarchical SDT models that we are
aware of addresses this problem correctly. Hence, our main goal was to
create a correct implementation of the general hierarchical linear
regression structure defined on SDT parameters. We argue that the
\code{bhsdtr} package for R \cite{rstatistical} provides exactly such
an implementation and we have made it publicly available at
\code{https://github.com/boryspaulewicz/bhsdtr}, together with the
annotated source code that was used to perform all the analyses and
produce all the figures presented in this paper.

In what follows, after introducing the most common version of the SDT
model, we describe its generalization, which can accommodate data from
rating experiments. Next, we explain briefly why, if a method of
inference for SDT models were to be of general use in psychology
studies, it is essential that it is based on a model equipped with the
general hierarchical linear regression structure. The \code{bhsdtr}
package meets this requirement thanks to a novel parametrization. We
describe this novel parametrization in great detail and explain how
reliance on relatively standard parametrization leads to problems in
the two other available implementations. We end the first part of this
paper with a formal definition of the model as implemented in
\code{bhsdtr}. The second part contains an overview of the package and
a tutorial in which we demonstrate how to use our method in
practice. Before we go any further, however, a note on terminology
seems in order.

In the context of hierarchical modelling, factors such as
participants, items, or replications are often referred to as
groups. In our opinion this naming convention may be confusing; a
single participant is both a group and a member of some group, while
at the same time the term "group" is perhaps most strongly associated
with study conditions, as in "experimental group". In this paper we
use the term "sampled factor" instead because, by virtue of being a
new term, it is unambiguous and seems descriptively correct: the term
"sampled factor" captures all the essential properties of such
variables, i.e., a nominal scale, the fact that values are sampled
from a larger population and are usually not of direct interest, as in
"this is only a sample", and that conclusions of statistical analysis
are meant to apply to the whole population of possible values.

\section{Equal-variance normal SDT model with additional criteria}

According to SDT, each stimulus in a classification task gives rise,
by some unspecified cognitive process, to a unidimensional internal
evidence value $s$ sampled from a distribution that depends on the
stimulus class. For historical reasons the two stimulus classes are
often referred to as "noise" and "signal", and task performance is
described in terms of hits, correct rejections, omissions, and false
alarms, but this terminology is appropriate only when the model is
applied to tasks that require detection, which is far from always
being the case. In the most widely used version of the model, shown in
Fig.~\ref{basicsdt}, the two evidence distributions are normal with
the same variance, which is usually fixed at unity to make the model
identifiable. The distance $d'$ between the means of the evidence
distributions represents sensitivity. Because normal distributions are
unbounded, $s$ is always ambiguous, and so a criterion $c$ placed on
the evidence axis has to be used to reach a binary decision. A
participant is assumed to decide that a stimulus belongs to the first
class (e.g., an old item) if $s < c$, or that it belongs to the second
class (e.g., a new item) if $s \geq c$. The location of the decision
criterion represents bias.

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{plot_basicsdt.pdf}
  \caption{Equal-variance normal Signal Detection Theory model}
  \label{basicsdt}
\end{figure}

Perhaps the simplest way of using this model is to fit it to observed
response counts and use the estimated $d'$ values in place of the
percent correct scores; if the model is correct, the resulting
performance measure is not contaminated by bias. Obviously, the model
may not be correct, which is one of the reasons why we focus more on
the generalized version shown in Fig.~\ref{sdtr} below.

% Model K >= 2

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{plot_sdtr.pdf}
  \caption{Equal-variance normal Signal Detection Theory model with
    additional criteria}
  \label{sdtr}
\end{figure}

This generalized model is applicable to studies in which participants
are asked to rate their binary classification decisions on confidence
or some other performance- or stimulus-related dimension. The ratings
and the binary classification decisions can be provided together
(e.g., "I am almost certain that it was a digit"), or in an arbitrary
order.

Ratings are accommodated by introducing additional criteria and
modelling a combined response $y$, which represents both the binary
classification decision and rating. The value of $y$ increases with
the strength of evidence in favor of the second stimulus class. For
example, if confidence is rated on a four-point scale, then $y = 1$
when a subject decides that a stimulus belongs to the first class with
certainty $4$, and $y = 5$ when a subject decides that a stimulus
belongs to the second class with certainty $1$. More formally, if $K$
is the number of possible combined responses, then a subject is
assumed to give response $k$ if $s \in (\bm{c}_{k-1},\bm{c}_k]$, where
$\bm{c}$ are the decision criteria, with $\bm{c}_0$ and $\bm{c}_K$
fixed at $-\infty$ and $+\infty$ respectively.

There is a good reason to collect the ratings and use the generalized
SDT model from Fig.~\ref{sdtr}, even when neither the ratings nor the
placement of criteria are relevant to the research problem. When
$K = 2$ (no ratings), the SDT model fits perfectly, regardless of
whether it is a reasonably good approximation to reality, because the
data and the model have the same dimensionality. This makes the
generalization to the case particularly important, as it is only when
$K > 2$ that the formal assumptions of the model (e.g., equal or
unequal variance) can be tested\footnote{In contrast to the formal
  assumptions, a psychological interpretation of the SDT parameters
  can be tested even when ratings are not available, e.g., by means of
  selective influence \cite{sternberg2001separate}}, which is often
done by comparing observed and predicted ROC curves.

When SDT models are used in psychology studies, researchers are
usually interested in relationships between SDT parameters and
additional measured or manipulated variables; a good example is the
dependence of $d'$ on stimulus strength. Also, in a great majority of
psychology studies in which classification tasks are used, the data
have a hierarchical structure, i.e., there are repeated measures for
each participant or item, and participants or items are only samples
from the target population. It seems worthwhile to explain why a
general-purpose method of inference for SDT models should accommodate
both kinds of situations.

\section{The importance of hierarchical regression structure}

If data have a hierarchical structure, but variability due to
subjects, items, or other sampled factors is not accounted for,
estimates of average (fixed) effects are not guaranteed to be unbiased
and conclusions are not guaranteed to generalize to the target
population. The not uncommon practice of analyzing data aggregated
over sampled factors represents an extreme case of ignoring
hierarchical data structure. The invalidity of this approach in the
context of SDT was clearly illustrated with the results of
simulational studies by \citeA{morey2008problematic}; however,
strictly speaking, it requires such demonstrations only in order to
make a point about a specific case. Because SDT is a non-linear model,
by definition, when estimates of its parameters are based on data
aggregated over sampled factors, the expected values of these
estimates are not in general true population averages. Such estimates
are biased and inference about a target population based on them is
simply not valid. To give a concrete example, consider two unbiased
participants, one with $d'_1 = 2$ and one with $d'_2 = 4$. Their
expected average accuracy is given by
$(\Phi(d'_1/2) + \Phi(d'_2/2)) / 2 = .91$, which corresponds to
$d' = 2.68$, whereas their true average $d'$ is $3$.

Aggregation is not the only way of ignoring a hierarchical data
structure. Sometimes non-aggregated data are analyzed by using
separate estimates for every participant $\times$ item $\times$
condition combination, but uncertainty due to distributions of subject
or item effects is not accounted for by means of a hierarchical model
structure. In such cases, conclusions -- at least with respect to the
uncertainties in estimates of population-average (fixed) effects are
guaranteed to be valid only for the given sample, not the target
population.

Another common source of problems is the separation of estimation of
non-linear model parameters from regression analyses which aim to
relate these parameters to measured or manipulated variables. When the
SDT parameters are estimated separately for each subject and
condition, and only later regressed on predictors of interest, a
number of additional issues may arise.

Firstly, the standard errors or credible intervals associated with the
regression coefficients do not reflect the uncertainty in the SDT
parameter estimates because the latter are treated as mere data
points. The precision of parameter estimates often varies between
participants, items, or conditions, but when the estimates are treated
as data points, no use is made of this information. Secondly,
regressing parameters on numeric predictors makes their estimates
dependent on the common regression structure, and so also on each
other, which can improve the quality of the estimates, just as
assuming that random effects are samples from a common distribution
may improve their estimates.

The aforementioned problems can be dealt with by supplementing the SDT
model with the general hierarchical linear regression structure. For
reasons that we will now explain, this can only be achieved if the
model is substantially reparametrized.

\section{Hierarchical Signal Detection Theory in a constrained
  parameter space}

Both $d'$ and $c$ have the virtue of being directly interpretable in
terms of sensitivity and bias. However, both $d'$ and $c$ are
constrained: $d'$ is non-negative and, when there is more than one
criterion, the elements of the $\bm{c}$ vector are order restricted
($\bm{c}_{i+1} > \bm{c}_i$). Because normal distribution is unbounded,
the hierarchical linear regression structure in which random effects
are normally distributed and fixed effects are represented by
unconstrained parameters can only be defined on unconstrained
parameters. We provide examples of the problems that may otherwise
arise in the following summary of hierarchical SDT implementations.

We are aware of only two attempts at creating a general-purpose method
of inference for hierarchical SDT models with ratings. One is the
Gibbs sampler proposed by \citeA{morey2008problematic} and the other
is the Hierarchical Meta-d' model (HMeta-d') proposed by
\citeA{hmetad}. The HMeta-d' model is a hierarchical version of the
meta-d' model \cite{maniscalco2012signal}, which in turn is a
generalization of the SDT model that allows for a separate
"meta-sensitivity" to account for possible discrepancies between a
binary stimulus classification (referred to as a type 1 task) and the
associated rating task (referred to as a type 2 or meta-cognitive
task). We consider HMeta-d' here because it reduces to the SDT model
with ratings when the type 1 and type 2 sensitivities are equal.

The Gibbs sampler created by \citeA{morey2008problematic} allows for
at most two sampled factors to have independent normally distributed
random effects on the evidence distribution means. Unlike $d'$, each
evidence distribution mean considered in isolation is an unconstrained
parameter, but the mean of the second evidence distribution is by
definition greater than ($d' > 0$) or equal to ($d' = 0$) the mean of
the first. The authors explicitly admit that their algorithm does not
enforce this restriction because, as they claim in the paper, it would
greatly complicate analysis. At the same time the authors fail to
mention that an immediate consequence of allowing for negative $d'$
values is that the resulting posterior distribution loses its intended
interpretation since it can have a non-zero mass when $d' < 0$. The
outermost criteria are fixed at $0$ and $1$, and the ordering
restriction is enforced by assuming that the likelihood is $0$
whenever $\bm{c}_{i+1} \leq \bm{c}_i$. As the authors explain, because
a sampled factor can have independent random effects on the evidence
distribution means, it can have an effect on all the criteria:
shifting both means by the same amount in the same direction is
equivalent to keeping the sensitivity intact, while shifting the
criteria relative to the evidence distributions. However, the elements
of the criteria vector cannot be affected differently by the same
sampled factor, which is an unrealistic restriction.

In HMeta-d' the hierarchical structure is restricted to normally
distributed random intercepts of one sampled factor. Perhaps the most
problematic aspect of the HMeta-d' model, apart from the fact that the
$d'$ parameter is allowed to assume negative values in this model
also, is the representation of the criteria. Each element of the
criteria vector has an associated independent normal distribution,
which does allow for criteria random effects, but does not enforce the
necessary ordering restriction. The elements of this vector are sorted
to obtain another criteria vector, and it is this sorted criteria
vector that is used to model the conditional combined response
distributions. Consequently, the model does contain parameters
representing the actual, order-restricted criteria, but, because
sorting is not injective, the space of the actual criteria is only
loosely related (i.e., not isomorphic) to the space of the
unrestricted criteria vectors that are associated with the
hierarchical structure.

\section{Hierarchical Signal Detection Theory in an unconstrained
  parameter space}

The general hierarchical linear regression structure can be defined on
SDT parameters only if the latter are derived from unconstrained
parameters. In the \code{bhsdtr} package, $d'$ is derived from
$\delta = \ln(d')$, thus random effects on $d'$ can be modelled by
assuming that $\delta$ is normally distributed. The problem of
representing the criteria by unconstrained parameters is solved by
mapping the $R^{K-1}$ space of unconstrained criteria vectors to the
$K$ dimensional probability simplex space using the softmax function,
and mapping the simplex space to the space of order-restricted
criteria vectors by means of the inverse normal CDF:

\begin{align}
  \bm{c}_i &= \Phi^{-1}(\sum_{k = 1}^i(e^{\bm{\gamma}_k}) /
             \sum_{j=1}^K(e^{\bm{\gamma}_j}))
\label{eq:1}
\end{align}

\noindent where $\Phi$ is the CDF of the standard normal distribution
and $\bm{\gamma} \in R^K$, with $\bm{\gamma}_K$ fixed at $0$ for
identifiability. The idea is illustrated in Fig.~\ref{fig:2} below:

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{plot.pdf}
  \caption{Mapping between the unconstrained $\bm{\gamma}$ vector and
    the criteria}
  \label{fig:2}
\end{figure}

Note that the normal distribution centered at the midpoint is merely a
mapping device, not a third evidence distribution, and that, for the
reasons that will soon become clear, it is wider than the two evidence
distributions. The mapping expressed by Eq.~\ref{eq:1} is an
isomorphism between the $R^{K-1}$ space and the space of
order-restricted criteria vectors. It's inverse is given by
$\gamma_i =\ln{(\int_{c_{i-1}}^{c_i} f(s) \,ds /
  \int_{c_{K-1}}^{\infty} f(s) \, ds)}$, where $f$ is the standard
normal probability density function. The elements of the $\bm{\gamma}$
vector correspond to relative distances between pairs of adjacent
criteria because their exponents represent the relative magnitudes of
areas under the standard normal curve, delineated by the pairs of
adjacent criteria:
$e^{\bm{\gamma}_i} / e^{\bm{\gamma}_j} = (\Phi(\bm{c}_i) -
\Phi(\bm{c}_{i-1})) / (\Phi(\bm{c}_j) - \Phi(\bm{c}_{j-1}))$. When
$K=2$, only $\bm{\gamma}_1$ is free to vary, and its value directly
represents the direction and magnitude of bias: $\bm{\gamma}_1$ is $0$
when the criterion is placed at the midpoint between the evidence
distributions; the more negative (positive) $\bm{\gamma}_1$ is, the
more the criterion is shifted to the left (right) of the midpoint.

It is often a good idea to multiply all the criteria by a value
greater than $1$, which is equivalent to making the mapping
distribution wider. This tends to even out values of $\bm{\gamma}$ by
preventing the outermost areas under the mapping distribution curve
from becoming very small, especially when the criteria are widely
spread, as can happen for moderate to large $d'$ values. This feature
is implemented in the \code{bhsdtr} package by introducing a scaling
factor.

Once $d'$ and $c$ are derived from the unconstrained $\delta$ and
$\gamma$ parameters, the SDT model can be supplemented with a
hierarchical linear regression structure. To avoid having to deal with
an even more complicated index notation\footnote{The reader familiar
  with hierarchical models may be surprised by our use of superscript
  parenthesized Greek letters to express hierarchical
  relationships. We chose this convention because it allowed us to use
  subscripts to denote elements of vectors and matrices while
  minimizing the number of nested sub- or superscripts.}, below we
present only the simple case of one sampled factor.

\begin{align*}
  \bm{\delta} &= \bm{X}^{(\delta)} \bm{\beta}^{(\delta)} + \bm{Z}^{(\delta)} \bm{\theta}^{(\delta)} \\
  \bm{d'}_i &= e^{\bm{\delta}_i} \\
  \bm{\gamma}_{i,\cdot} &= \bm{X}^{(\gamma)}_{i,\cdot} \bm{\beta}^{(\gamma)} + \bm{Z}^{(\gamma)}_{i,\cdot}
                      \bm{\theta}^{(\gamma)} \\
  \bm{c}_{i,k} &= s \ \Phi^{-1}(\sum_{l = 1}^k(e^{\bm{\gamma}_{i,l}}) /
                 \sum_{m=1}^K(e^{\bm{\gamma}_{i,m}})) \\
  p(\bm{y}_i = k|\bm{stim}_i = 1) &= \Phi(\bm{c}_{i,k} + \bm{d'}_i / 2) - \Phi(\bm{c}_{i,k-1} + \bm{d'}_i / 2) \\
  p(\bm{y}_i = k|\bm{stim}_i = 2) &= \Phi(\bm{c}_{i,k} - \bm{d'}_i / 2) - \Phi(\bm{c}_{i,k-1} - \bm{d'}_i / 2)
\end{align*}

\noindent Here $i = 1\dots N$ is the observation number, $\bm{X}$ is
the fixed effects model matrix for the respective parameter, $\bm{Z}$
is the random effects model matrix, $\bm{\beta}$ and $\bm{\theta}$ are
the fixed and random effects, $\bm{c}$ is an $N \times K-1$ matrix,
$s$ is the criteria scaling factor, and $\bm{y}$ is the combined
response. Note that $\bm{d'}_i$ is a scalar, but
$\bm{\gamma}_{i,\cdot}$ is in general a vector, and so
$\bm{\beta}^{(\gamma)}$ and $\bm{\theta}^{(\gamma)}$ are matrices. The
$j$-th rows of the $\bm{\beta}^{(\gamma)}$ and
$\bm{\theta}^{(\gamma)}$ matrices represent fixed and random effects
on the $j$-th element of the $\bm{\gamma}$ vector.

Following \citeA{sorensen2015bayesian} we make use of the Cholesky
decomposition of the correlation matrices because it improves
efficiency and admits a convenient prior on random effects
correlations:

\begin{align*}
  \text{vectorized}(\bm{\theta}^{(\gamma)}) &= \text{diag}(\bm{\tau}^{(\gamma)}) \bm{L}^{(\gamma)} \bm{z}^{(\gamma)} \\
  \bm{\theta}^{(\delta)} &= \text{diag}(\bm{\tau}^{(\delta)}) \bm{L}^{(\delta)} \bm{z}^{(\delta)} \\
  \bm{z}^{(\delta)}_i &\sim \text{Normal}(0, 1) \\
  \bm{z}^{(\gamma)}_j &\sim \text{Normal}(0, 1)
\end{align*}

\noindent where each $\bm{\tau}$ is a vector of standard deviations of
random effects and each $\bm{L}$ is a Cholesky decomposition of a
random effects correlation matrix, i.e., $\bm{C} = \bm{L}
\bm{L}'$. Thus, $\bm{\theta}$ is multivariate normal with covariance
matrix $\text{diag}(\bm{\tau}) \bm{L}$.

Finally, we use weakly informative proper priors because they provide
regularization and help stabilize computation. The fixed effects
$\bm{\beta}^{(\delta)}$ and $\bm{\beta}^{(\gamma)}$ are given
independent normal priors, the random effects standard deviations
$\bm{\tau}^{(\delta)}$ and $\bm{\tau}^{(\gamma)}$ are given
independent half-Cauchy priors, as recommended by
\citeA{gelman2004prior}, and each $\bm{L}$ is given an independent lkj
prior:

\begin{align*}
  \bm{\beta}^{(\delta)}_i &\sim \text{Normal}(\bm{\mu}^{(\delta)}_i, \bm{\sigma}^{(\delta)}_i) \\
  \bm{\beta}^{(\gamma)}_{k,l} &\sim \text{Normal}(\bm{\mu}^{(\gamma)}_{k,l}, \bm{\sigma}^{(\gamma)}_{k,l}) \\
  \bm{\tau}^{(\delta)}_i &\sim \text{half-Cauchy}(0, \bm{\zeta}^{(\delta)}_i) \\
  \bm{\tau}^{(\gamma)}_{k,l} &\sim \text{half-Cauchy}(0, \bm{\zeta}^{(\gamma)}_{k,l}) \\
  \bm{L}^{(\delta)} &\sim \text{lkj}(\nu^{(\delta)}) \\
  \bm{L}^{(\gamma)} &\sim \text{lkj}(\nu^{(\gamma)}) \\
\end{align*}

\section{Specifying the prior distributions}

The formal definition of a Bayesian model is not complete without
providing fixed values of all the parameters that define prior
distributions. Specifying the priors on sensitivity effects does not
pose any special difficulties. The sensitivity of an unbiased
classifier given percent correct (pc) is given by
$2 \Phi^{-1}(\text{pc})$. When $p(stim = 1) = 0.5$, the greater the
bias, the lower the accuracy, meaning that an unbiased sensitivity is
a lower bound on sensitivity given percent correct. Let us assume that
the majority of subjects are expected to achieve percent correct
within the $.51$ to $.99$ range, with negligible bias. Since
$\ln(2\Phi^{-1}(.51)) = -2.99$ and $\ln(2 \Phi^{-1}(.99)) = 1.54$, a
reasonable weakly informative prior on $\delta$ is normal with mean
$(1.54 - 2.99) / 2$ and standard deviation $(1.54 + 2.99) / 2$, which
is the default prior on delta effects in the \code{bhsdtr} package.

Specifying the priors on criteria effects can be challenging because
the criteria are order-restricted and the complexity of the mapping
expressed by Eq.~\ref{eq:1} makes it difficult to reason about priors
on $\bm{\gamma}$ in terms of criteria effects. By default, in the
\code{bhsdtr} package each entry in the $\bm{\sigma}^{(\gamma)}$ and
$\bm{\zeta}^{(\gamma)}$ matrices is set to $\ln(100)$ and the criteria
scaling factor is fixed at $2$.

The prior on random effects standard deviations is parametrized by
$\bm{\zeta}$, which represents half-width at half-maximum of the
half-Cauchy distribution. In our opinion, a not-unreasonable starting
point is to set $\bm{\zeta}$ at the value that is greater or equal to
the most likely value of the random effects standard deviation.

Finally, by default $\nu^{(\delta)} = \nu^{(\gamma)} = 1$, which
implies a uniform prior on random effects correlation
matrices. Because the greater the value of $\nu$, the more emphasis is
put on zero off-diagonal correlations, the researcher can force the
correlations to be near-zero by choosing a large $\nu$ value.

\section{Overview of the software implementation}

The \code{bhsdtr} package implements the model described in the
previous section in the Stan modelling language because it uses a
state-of-the-art adaptive Hamiltonian Monte Carlo sampling algorithm
which often handles high-dimensional correlated posteriors better than
a Gibbs sampler. Our package is essentially a collection of documented
functions: The \code{aggregate\_responses} function aggregates data as
much as possible for efficiency, but without distorting the
hierarchical structure. The \code{make\_stan\_model} function creates a
model definition in the Stan language. The Stan code produced by the
\code{make\_stan\_model} function can be fitted as is or modified by the
user if needed, e.g., to change the prior distributions or to drop the
equal variance assumption. The \code{make\_stan\_data} function creates
regression model matrices and other data structures required by the
model created using the \code{make\_stan\_model} function. Finally, the
\code{plot\_sdt\_fit} function can be used to visually assess the fit of
the model by creating publication-ready ROC curve plots or response
distribution plots with posterior predictive intervals calculated for
the chosen $\alpha$ level.

\subsection{Usage example: installing the package and testing the
  model on real data}

To make full use of the bhsdtr package functionality, three
non-standard R packages are required, namely \code{rstan},
\code{plyr}, and \code{ggplot2}. We recommend using the
\code{devtools} package to install the \code{bhsdtr} package directly
from the github repository. This will automatically install any
missing required packages:

\begin{lstlisting}{language = R}
  devtools::install_git('git://github.com/boryspaulewicz/bhsdtr')
  library(bhsdtr)
\end{lstlisting}

We will now explain how to perform some of the essential steps of a
typical data analysis process, which at the very least will usually
involve preparing the data, creating the model code, fitting the
model, assessing the fit, and possibly converting the unconstrained
$\delta$ and $\gamma$ parameters to $d'$ and $c$.

\subsubsection{Preparing the data}

The \code{bhsdtr} package contains a dataset, \code{gabor}, from an
unpublished study in which on each trial the participants had to
classify a briefly presented Gabor patch as tilted to the left or to
the right using the arrow keys. The participants were also asked to
rate the stimuli on a 4-point Perceptual Awareness Scale
\cite{ramsoy2004introspection} presented at the bottom of the
screen. The Gabor patch was immediately followed by a mask. The PAS
ratings ranged from "no experience" to "absolutely clear image" and
were provided either before (RD order condition) or after (DR order
condition) the arrow keys were pressed. On each trial the Gabor patch
was equally likely to be presented for 32 ms or 64 ms. Order was a
between-subject variable and duration was a within-subject
variable. There were 47 participants and 48 trials per condition.

In the study in question, the response was originally encoded using
separate variables for accuracy and rating, so the first step was to
create an appropriate response variable using the
\code{combined\_response} function. This function requires three
variables, one encoding the stimulus class, one encoding the rating
(as an integer), and one binary variable encoding the decision
accuracy.

\begin{lstlisting}{language=R}
  gabor$resp = combined_response(gabor$stim, 
                                 gabor$rating, 
                                 gabor$acc)
\end{lstlisting}

This step is required only if the ratings are available and a combined
response variable is not already present in the data. In the single
criterion case, the combined response variable is simply the binary
classification decision. To fit a single-criterion SDT model to this
dataset, the code above would have to be replaced with the following:

\begin{lstlisting}{language=R}
  gabor$resp = combined_response(gabor$stim, 
                                 accuracy = gabor$acc)
\end{lstlisting}

Next, the data has to be aggregated using the
\code{aggregate\_responses} function, but only to an extent that
preserves all the random effects. This function requires as arguments
a data frame containing all the relevant variables, the name of the
stimulus class variable, the name of the combined response variable,
and the vector of the names of all the variables that are to be
preserved in the resulting aggregated dataset (apart from the stimulus
class variable and the combined response variable), i.e., those
encoding the sampled factors and those representing the independent
variables used in the regression part of the model:

\begin{lstlisting}{language=R}
adata = aggregate_responses(gabor, 'stim', 'resp', 
                            c('id', 'duration', 'order'))  
\end{lstlisting}

The main purpose of the aggregation step is to improve the efficiency
of sampling from the posterior distribution. When data are aggregated
in this way, the likelihood for each condition $\times$ participant
combination has to be computed only once rather than as many times as
there are trials per condition per participant. Note that if there are
other sampled factors present in the data (e.g., items, replications,
etc.), then these factors also have to be specified at this stage to
preserve the hierarchical data structure. The
\code{aggregate\_responses} function creates a list with three
components. The \code{data} component is a data frame containing
additional preserved variables, the \code{stimulus} component is the
stimulus class variable, and the \code{counts} component is an
$N\times K$ matrix of combined response counts, where $N$ is the
number of data points and $K$ is the number of possible combined
response values.

\subsubsection{Creating the model code}

A model is fitted using the \code{stan} function from the \code{rstan}
package. This function requires a special list of data structures used
by the model as well as a model specification expressed in the Stan
language. Every model has some fixed effects structure since, even
when there are no predictors, the model parameters can be expressed as
regressed on a vector of ones (i.e., an intercept). However, many
models also have a hierarchical structure and, if that is the case,
this hierarchical structure has to be specified when using the
\code{make\_stan\_model} function. This is done by providing a list of
lists of R model formulae. Each list of model formulae is composed of
at least three elements and specifies the correlated random effects of
one sampled factor. The \code{group} element specifies the sampled
factor; the \code{delta} and \code{gamma} elements specify which
effects are assumed to vary between the levels of this sampled
factor. When \code{make\_stan\_model} is used without any arguments, it
specifies a model without any random effects. Fixed effects model
matrices are specified by providing a list with at least two model
formulae, named \code{delta} and \code{gamma}, to the
\code{make\_stan\_data} function that is described later in this
paper. Non-default priors can be specified by adding optional elements
to the random and fixed effects specification lists, as described in
the \code{make\_stan\_data} function documentation.

In the study in question there was only one sampled factor, i.e., the
participants. Because duration was a within-participant variable, in
principle its effect could vary between the participants for all the
SDT parameters. However, a preliminary data analysis indicated that
the barely noticeable 32 ms difference in duration seemed to affect
only the sensitivity. Thus, it was assumed that $\delta$ may depend on
duration and order, but $\gamma$ may only be affected by
order. Because duration was a within-subjects variable, its effect on
$\delta$ was assumed to vary between the participants, but the only
random effect associated with $\gamma$ was the intercept:

\begin{lstlisting}{language=R}
fixed = list(delta = ~ -1 + duration:order, 
             gamma = ~ order)
random = list(list(group = ~ id, 
              delta = ~ -1 + duration, 
              gamma = ~ 1))
model = make_stan_model(random)
\end{lstlisting}

The \code{make\_stan\_data} function creates fixed and random effect
model matrices based on the respective model formulae using dummy
contrast coding. Note that the implicit intercept was suppressed for
the $\delta$ model matrix. In this way, $\delta$ was estimated for
every duration $\times$ order condition. The resulting separate
intercepts and slopes parametrization makes it easier to calculate
arbitrary contrasts on posterior samples. A more standard
parametrization was used for the $\gamma$ parameter because it was
initially assumed that the criteria depend only on order, and so there
was only one contrast of interest for every element of the $\gamma$
vector. On the other hand, in such cases nested parametrization (with
separate intercepts and slopes for every condition) may be more
convenient if a researcher is interested in the actual criteria, as we
will later explain when introducing the \code{gamma\_to\_crit}
function. This example also illustrates how the separation of the
$\delta$ and $\gamma$ regression structures makes it possible to test
a broad class of linear models representing the dependence of the SDT
parameters on additional variables.

\subsubsection{Fitting the model}

In order to fit the model, a separate data structure used by the Stan
sampler has to be created using the \code{make\_stan\_data}
function. The obligatory arguments to this function are an aggregated
data object created by the \code{aggregate\_responses} function and a
fixed effects specification. Importantly, if random effects are
modelled, the same specification of random effects has to be provided
to the \code{make\_stan\_model} and \code{make\_stan\_data} functions.

\begin{lstlisting}{language=R}
sdata = make_stan_data(adata, fixed, random)
\end{lstlisting}

Finally, a vector of names of parameters of interest has to be
specified when calling the \code{stan} function:

\begin{lstlisting}{language=R}
fit = stan(model_code = model,
           data = sdata,
           pars = c('delta_fixed', 'gamma_fixed',
                    'delta_sd_1', 'gamma_sd_1',
                    'delta_random_1', 'gamma_random_1',
                    'Corr_delta_1', 'Corr_gamma_1',
                    'counts_new'),
           iter = 8000,
           chains = 4)
\end{lstlisting}

Note that since more than one sampled factor is allowed, the names of
all the hierarchical parameters are indexed (e.g., \code{delta\_sd\_1},
\code{delta\_random\_1}, \code{Corr\_delta\_1}). The name
\code{counts\_new} refers to posterior predictive samples that are
required by the \code{plot\_sdt\_fit} function. Names starting with
\code{Corr} refer to random effects correlation matrices, which are
computed from Cholesky decompositions.

\subsubsection{Assessing the model fit}

Four chains of 8,000 iterations each were run simultaneously; the
first half of the posterior samples, which served as a warm-up period
for tuning the parameters of the sampling algorithm, was
discarded. Part of the resulting Stan output is presented in
Table~\ref{fitsum} below.

\begin{table}[H]
\caption{Model fit summary statistics}
\begin{tabular}{rrrrrrrr}
  % \hline
  & mean & $SE_{mean}$ & $SD$ & $2.5\%$ & $97.5\%$ & No. eff. samples & $\hat{R}$ \\ 
  \hline
  delta\_fixed[1] & -0.10 & 0.00 & 0.15 & -0.41 & 0.18 & 4626 & 1.00 \\ 
  delta\_fixed[2] & 1.12 & 0.00 & 0.09 & 0.95 & 1.29 & 4764 & 1.00 \\ 
  delta\_fixed[3] & -0.39 & 0.00 & 0.20 & -0.80 & -0.03 & 5427 & 1.00 \\ 
  delta\_fixed[4] & 1.28 & 0.00 & 0.11 & 1.06 & 1.50 & 5464 & 1.00 \\ 
  gamma\_fixed[1,1] & -0.14 & 0.00 & 0.06 & -0.27 & -0.02 & 2925 & 1.00 \\ 
  gamma\_fixed[1,2] & -0.22 & 0.00 & 0.10 & -0.42 & -0.01 & 8199 & 1.00 \\ 
  gamma\_fixed[2,1] & -0.70 & 0.00 & 0.18 & -1.05 & -0.35 & 3060 & 1.00 \\ 
  gamma\_fixed[2,2] & 0.49 & 0.00 & 0.29 & -0.06 & 1.04 & 3452 & 1.00 \\ 
  gamma\_fixed[3,1] & -0.54 & 0.00 & 0.22 & -0.96 & -0.11 & 3103 & 1.00 \\ 
  gamma\_fixed[3,2] & 0.83 & 0.01 & 0.35 & 0.14 & 1.51 & 3086 & 1.00 \\ 
  gamma\_fixed[4,1] & 0.28 & 0.00 & 0.25 & -0.20 & 0.76 & 3090 & 1.00 \\ 
  gamma\_fixed[4,2] & 0.42 & 0.01 & 0.40 & -0.37 & 1.22 & 3291 & 1.00 \\ 
  gamma\_fixed[5,1] & -0.21 & 0.01 & 0.30 & -0.80 & 0.37 & 3440 & 1.00 \\ 
  gamma\_fixed[5,2] & 0.83 & 0.01 & 0.48 & -0.10 & 1.78 & 3637 & 1.00 \\ 
  gamma\_fixed[6,1] & -0.77 & 0.00 & 0.24 & -1.23 & -0.31 & 3378 & 1.00 \\ 
  gamma\_fixed[6,2] & 0.80 & 0.01 & 0.38 & 0.05 & 1.56 & 3316 & 1.00 \\ 
  gamma\_fixed[7,1] & -0.32 & 0.00 & 0.16 & -0.64 & 0.01 & 3346 & 1.00 \\ 
  gamma\_fixed[7,2] & 0.42 & 0.00 & 0.28 & -0.11 & 0.98 & 3333 & 1.00 \\ 
  delta\_sd\_1[1] & 0.66 & 0.00 & 0.11 & 0.48 & 0.90 & 6373 & 1.00 \\ 
  delta\_sd\_1[2] & 0.44 & 0.00 & 0.05 & 0.35 & 0.56 & 5463 & 1.00 \\ 
  gamma\_sd\_1[1] & 0.16 & 0.00 & 0.08 & 0.02 & 0.31 & 2071 & 1.00 \\ 
  gamma\_sd\_1[2] & 0.82 & 0.00 & 0.11 & 0.62 & 1.06 & 5852 & 1.00 \\ 
  gamma\_sd\_1[3] & 1.08 & 0.00 & 0.12 & 0.86 & 1.33 & 4293 & 1.00 \\ 
  gamma\_sd\_1[4] & 1.27 & 0.00 & 0.14 & 1.03 & 1.57 & 3723 & 1.00 \\ 
  gamma\_sd\_1[5] & 1.55 & 0.00 & 0.17 & 1.24 & 1.91 & 4297 & 1.00 \\ 
  \dots{} & \dots{} & \dots{} & \dots{} & \dots{} & \dots{} & \dots{} & \dots{} \\
  \hline
\end{tabular}
\label{fitsum}
\end{table}

As can be seen, given the complexity of the model, the chains
exhibited good mixing and seemed to have converged; there were enough
effective samples of the fixed effect parameters to estimate $95\%$
credible intervals well and none of the Gelman-Rubin $\hat{R}$
statistics crossed the conventional $1.01$ threshold, suggesting
negligible sensitivity to the initial values.

Figs.~\ref{fig:6} and \ref{fig:7} below contain normal
quantile-quantile plots of random effects. The plots indicate that the
normally distributions of random $\delta$ and $\gamma$ effects can be
approximated by normal distributions and that these parameters seem to
be good candidates for representing variability in the sensitivity and
criteria parameters due to the sampled factors.

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{delta_qq_plot.pdf}
  \caption{Normal quantile-quantile plots of $\delta$ random effects}
  \label{fig:6}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{gamma_qq_plot.pdf}
  \caption{Normal quantile-quantile plots of $\gamma$ random effects}
  \label{fig:7}
\end{figure}

Once enough good quality posterior samples are obtained for the
parameters of interest, the inference process can be carried out by
calculating credible intervals, HPD intervals, or Bayes factors for
any function of the parameters. However, even when the stan output
summary does not indicate sampler convergence issues, before drawing
any further conclusions the researcher should first check if the model
fits the data. The \code{plot\_sdt\_fit} function can be used for this
purpose:

\begin{lstlisting}{language = R}
plot_sdt_fit(fit, adata, c('order', 'duration')))
\end{lstlisting}

This function requires at least three arguments: a \code{stanfit}
object, an aggregated data list produced by the
\code{aggregate\_responses} function that was used to produce the
stanfit object, and a vector of names of variables that will determine
how the data will be partitioned before plotting. We recommend
assessing the fit at the individual level, but we did not include the
participant identification number in the list of conditioning
variables because the resulting plot would take up too much space.

As can be seen in Fig.~\ref{fig:3}, which shows the ROC curves
produced by the code above, the model seemed to fit the data well in
all but one condition (decision after rating, 64 ms duration), in
which three out of seven relevant\footnote{The point in the
  upper-right corner of a ROC curve is always in the $(1,1)$ position}
points were outside the two-dimensional $95\%$ posterior predictive
regions.

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{roc_fit.pdf}
  \caption{ROC curve fit}
  \label{fig:3}
\end{figure}

Another way to assess model fit visually is by inspecting the
conditional response distributions ($p(y|stim)$), such as those shown
in Fig.~\ref{fig:4}, which was also created using the
\code{plot\_sdt\_fit} function.

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{response_fit.pdf}
  \caption{Response distribution fit}
  \label{fig:4}
\end{figure}

This kind of plot can be informative about the reasons why a model
does not fit the data. In this particular case, the plot seems to
suggest that it may be a good idea to inspect the fit at the
individual level and see if there are some participants with unusual
$p(y|stim=1)$ distributions in the RD $\times$ 64 ms condition. On the
other hand, it is also possible that the lack of fit is mainly a
consequence of the assumption that duration had zero effect on
$\bm{\gamma}$, or that more substantial modifications are necessary,
such as dropping the equal variance assumption.

\subsubsection{Converting unconstrained $\delta$ and $\gamma$
  parameters to sensitivities and criteria}

Posterior $\delta$ and $\gamma$ samples have to be transformed in
order to work with the $d'$ and $c$ parameters. This is
straightforward only when fixed effects represent average parameter
values in separate conditions, not differences between conditions or
regression slopes. In our example, because nested parametrization was
used for the $\delta$ fixed effects model matrix, all four
\code{delta\_fixed} parameters can easily be transformed to
sensitivities by applying the exponential function. It is important to
remember that because this is a non-linear transformation, the
$\delta$ to $d'$ conversion step should be done first before applying
any other transformations to the posterior samples; for example, the
exponential of a point and interval estimate is not equal to the point
and interval estimate calculated after transforming the $\delta$
posterior samples to the $d'$ samples.

In this case the first column of the \code{gamma\_fixed} parameter
matrix (the intercept) corresponds to the values of the $\bm{\gamma}$
vector in the DR condition, but the second column corresponds to the
\emph{effect} of order on $\bm{\gamma}$. For this reason, in this
particular case the posterior criteria samples can be obtained using
the \code{gamma\_to\_crit} function only for the first column of the
\code{gamma\_fixed} matrix.

\subsection{Testing the model on simulated data}

To test if the model correctly recovers known parameter values, we
simulated the data from a hypothetical exact replication of the
previously described experiment using the point estimates from the
previous fit as known realistic parameter values. Mixing performance
was similar to the real data case. All the model parameters were
correctly recovered in a sense that the true values were outside the
$95\%$ credible intervals no more than $5\%$ of the time.

For illustration purposes, an SDT model that differed from the true
model only in that it did not have any hierarchical structure was
fitted to the same simulated dataset. Since the non-hierarchical model
was much simpler and the data consisted of only eight vectors of
response counts, the mixing of the chains was excellent.

The $95\%$ credible intervals calculated for the fixed effects based
on each model are compared in Fig.~\ref{fig:5} below. The estimates
were centered on the true values to simplify the presentation. As can
be seen, the true model correctly recovered the known parameter
values, but the estimates based on the simplified, non-hierarchical
model were biased; the credible intervals were not only about three
times shorter on average, but also failed to contain most of the true
values.

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{true_vs_nonhier.pdf}
  \caption{Comparison of the point and interval posterior estimates
    based on the true hierarchical and the simplified non-hierarchical
    models}
  \label{fig:5}
\end{figure}

However, as can be seen in Fig.~\ref{fig:8} below, in this case the
observed ROC curves seemed to fit the simplified model's predictions
quite well, giving a false impression of model validity.

\begin{figure}[H]
  \centering
  \includegraphics[width=.8\linewidth]{roc_sim_aggr_fit.pdf}
  \caption{ROC curve fit for the non-hierarchical model}
  \label{fig:8}
\end{figure}

\section{Concluding remarks}

The great importance of SDT to psychology stems from the fact that
given weak assumptions about an underlying decision process, it
promises to deconfound sensitivity from bias in arbitrary binary
classification tasks. To the best of our knowledge, at present the
\code{bhsdtr} package provides the only method of Bayesian inference
for SDT models with or without ratings that can be recommended as a
default choice in typical applications. Our parametrization forces the
sensitivity to be non-negative and the criteria to be
order-restricted, while the isomorphisms between the $d'$ and $c$
parameters and the unconstrained $\delta$ and $\gamma$ parameters make
it possible to supplement the SDT model with the general hierarchical
linear regression structure. There is no limit to the number of
sampled factors except for the one imposed by available computational
resources; correlations of random effects of the same sampled factor
are accounted for, all the SDT parameters can be modelled by linear
regression within the same model, and all the effects on all the SDT
parameters estimable within the levels of the sampled factors can have
associated random effects. If the need arises to relax a built-in
restriction, experienced users can extend the model in arbitrary ways
by using automatically generated human-readable Stan code as a
template. We hope that researchers with a basic understanding of
Signal Detection Theory, Bayesian inference, and hierarchical
modelling will find our package useful and adopt it as a method of
analysis of binary classification performance in future studies.

\bibliography{/home/borys/cs/literatura}

\end{document}
